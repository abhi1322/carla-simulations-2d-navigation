{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779634c4-5528-46df-9fa1-42dbbf3a3eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Connect to the CARLA simulator\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "# client.set_timeout(10.0)\n",
    "world = client.get_world()\n",
    "\n",
    "# Spawn a vehicle\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = blueprint_library.filter(\"model3\")[0]\n",
    "spawn_point = world.get_map().get_spawn_points()[0]\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n",
    "# Camera sensor types\n",
    "sensor_types = [\n",
    "    {\"type\": \"sensor.camera.rgb\", \"name\": \"RGB Camera\"},\n",
    "    {\"type\": \"sensor.camera.depth\", \"name\": \"Depth Camera\"},\n",
    "    # {\"type\": \"sensor.camera.semantic_segmentation\", \"name\": \"Semantic Camera\"},\n",
    "    # {\"type\": \"sensor.camera.instance_segmentation\", \"name\": \"Instance Camera\"},\n",
    "    # {\"type\": \"sensor.camera.dvs\", \"name\": \"DVS Camera\"},\n",
    "    # {\"type\": \"sensor.camera.optical_flow\", \"name\": \"Optical Flow Camera\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7686d1-05e7-46c5-8596-12a68d6f2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_data = [None] * len(sensor_types)  # Placeholder for images from each sensor\n",
    "\n",
    "def camera_callback(image, index):\n",
    "    \"\"\"Callback function to process camera images.\"\"\"\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    if sensor_types[index][\"type\"] == \"sensor.camera.depth\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 0]  # Depth channel\n",
    "        array = (array * 255 / np.max(array)).astype(np.uint8)  # Normalize depth\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.semantic_segmentation\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 2]  # Semantic channel\n",
    "        array = cv2.applyColorMap(array, cv2.COLORMAP_JET)  # Colorize\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.instance_segmentation\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 2]  # Instance segmentation\n",
    "        array = cv2.applyColorMap(array, cv2.COLORMAP_PARULA)  # Colorize\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.dvs\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, :3]  # DVS (RGB event data)\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.optical_flow\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, :2]  # Optical flow (UV channels)\n",
    "        array = np.linalg.norm(array, axis=2).astype(np.uint8)  # Combine flow vectors\n",
    "    else:\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, :3]  # RGB\n",
    "    camera_data[index] = array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d3e1d1-b422-466a-b301-a2c15592dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Camera attributes\n",
    "camera_bp = blueprint_library.find(\"sensor.camera.rgb\")\n",
    "camera_bp.set_attribute(\"image_size_x\", \"640\")\n",
    "camera_bp.set_attribute(\"image_size_y\", \"480\")\n",
    "camera_bp.set_attribute(\"sensor_tick\", \"0.1\")  # 10 FPS\n",
    "\n",
    "# Spawn cameras\n",
    "cameras = []\n",
    "for i, sensor in enumerate(sensor_types):\n",
    "    sensor_bp = blueprint_library.find(sensor[\"type\"])\n",
    "    sensor_bp.set_attribute(\"image_size_x\", \"640\")\n",
    "    sensor_bp.set_attribute(\"image_size_y\", \"480\")\n",
    "    sensor_bp.set_attribute(\"sensor_tick\", \"0.1\")\n",
    "    transform = carla.Transform(carla.Location(x=1.5 + i * 0.2, z=2.4))  # Slight offset for each camera\n",
    "    camera = world.spawn_actor(sensor_bp, transform, attach_to=vehicle)\n",
    "    camera.listen(lambda image, idx=i: camera_callback(image, idx))  # Pass index to callback\n",
    "    cameras.append(camera)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f54542-a805-4c30-ba3a-486b64654319",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Ensure all cameras have captured frames\n",
    "        if all(data is not None for data in camera_data):\n",
    "            # Resize images for visualization\n",
    "            resized_images = [cv2.resize(img, (320, 240)) for img in camera_data]\n",
    "\n",
    "            # Combine images into a single grid (2 rows x 3 columns)\n",
    "            combined_view = np.vstack([\n",
    "                np.hstack(resized_images[:3]),\n",
    "                np.hstack(resized_images[3:])\n",
    "            ])\n",
    "\n",
    "            # Display the combined view\n",
    "            cv2.imshow(\"Camera Sensor Views\", combined_view)\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    for camera in cameras:\n",
    "        camera.destroy()\n",
    "    vehicle.destroy()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa197144-8893-4e53-8bf2-04aaf41c5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f730c753-de55-4b59-8252-444e5211bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to the CARLA simulator\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "client.set_timeout(10.0)\n",
    "world = client.get_world()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c6c6b1-54f9-48cc-b3c0-d4387c64c55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34118"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce simulation quality\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True  # Enable synchronous mode for better control\n",
    "settings.fixed_delta_seconds = 0.5  # Lower tick rate\n",
    "world.apply_settings(settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4588a09-53ed-43e6-a122-5a77ccef7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn a vehicle\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = blueprint_library.filter(\"model3\")[0]\n",
    "spawn_point = world.get_map().get_spawn_points()[0]\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2141251c-691e-4bd3-a4fd-5dfc3cae9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the spectator to follow the vehicle\n",
    "\n",
    "spectator = world.get_spectator()\n",
    "spectator.set_transform(carla.Transform(\n",
    "    carla.Location(x=0, y=0, z=50),\n",
    "    carla.Rotation(pitch=-90)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b44569-7f5e-4b83-91c7-b8ddc004a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Camera sensor types\n",
    "sensor_types = [\n",
    "    {\"type\": \"sensor.camera.rgb\", \"name\": \"RGB Camera\"},\n",
    "    {\"type\": \"sensor.camera.depth\", \"name\": \"Depth Camera\"},\n",
    "    {\"type\": \"sensor.camera.semantic_segmentation\", \"name\": \"Semantic Camera\"},\n",
    "    {\"type\": \"sensor.camera.instance_segmentation\", \"name\": \"Instance Camera\"},\n",
    "]\n",
    "\n",
    "camera_data = [None] * len(sensor_types)  # Placeholder for images from each sensor\n",
    "\n",
    "def camera_callback(image, index):\n",
    "    \"\"\"Callback function to process camera images.\"\"\"\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    if sensor_types[index][\"type\"] == \"sensor.camera.depth\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 0]  # Depth channel\n",
    "        array = (array * 255 / np.max(array)).astype(np.uint8)  # Normalize depth\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.semantic_segmentation\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 2]  # Semantic channel\n",
    "        array = cv2.applyColorMap(array, cv2.COLORMAP_JET)  # Colorize\n",
    "    elif sensor_types[index][\"type\"] == \"sensor.camera.instance_segmentation\":\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, 2]  # Instance segmentation\n",
    "        array = cv2.applyColorMap(array, cv2.COLORMAP_PARULA)  # Colorize\n",
    "    else:\n",
    "        array = array.reshape((image.height, image.width, 4))[:, :, :3]  # RGB\n",
    "    camera_data[index] = array\n",
    "\n",
    "# Camera attributes (reduce resolution for better performance)\n",
    "camera_bp = blueprint_library.find(\"sensor.camera.rgb\")\n",
    "camera_bp.set_attribute(\"image_size_x\", \"320\")  # Reduced resolution\n",
    "camera_bp.set_attribute(\"image_size_y\", \"240\")  # Reduced resolution\n",
    "camera_bp.set_attribute(\"sensor_tick\", \"0.1\")  # 10 FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd75b10a-2369-42ac-bc1d-8d2094fd9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn cameras\n",
    "cameras = []\n",
    "for i, sensor in enumerate(sensor_types):\n",
    "    sensor_bp = blueprint_library.find(sensor[\"type\"])\n",
    "    sensor_bp.set_attribute(\"image_size_x\", \"320\")\n",
    "    sensor_bp.set_attribute(\"image_size_y\", \"240\")\n",
    "    sensor_bp.set_attribute(\"sensor_tick\", \"0.5\")\n",
    "    transform = carla.Transform(carla.Location(x=0.8, z=1.7))  # Fixed position for all cameras\n",
    "    camera = world.spawn_actor(sensor_bp, transform, attach_to=vehicle)\n",
    "    camera.listen(lambda image, idx=i: camera_callback(image, idx))  # Pass index to callback\n",
    "    cameras.append(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5799b5e4-c967-442b-a675-30280372b198",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7328\\2495903832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Combine images into a single grid (2 rows x 2 columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             combined_view = np.vstack([\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             ])\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\carla-sim\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Update the spectator to follow the vehicle\n",
    "        transform = vehicle.get_transform()\n",
    "        spectator.set_transform(carla.Transform(\n",
    "            transform.location + carla.Location(z=20, x=-5),  # Adjusted for a top-down view\n",
    "            carla.Rotation(pitch=-20)\n",
    "        ))\n",
    "\n",
    "        # Ensure all cameras have captured frames\n",
    "        if all(data is not None for data in camera_data):\n",
    "            # Resize images for visualization\n",
    "            resized_images = [cv2.resize(img, (160, 120)) for img in camera_data]\n",
    "\n",
    "            # Combine images into a single grid (2 rows x 2 columns)\n",
    "            combined_view = np.vstack([\n",
    "                np.hstack(resized_images[:2]),\n",
    "                np.hstack(resized_images[2:])\n",
    "            ])\n",
    "\n",
    "            # Display the combined view\n",
    "            cv2.imshow(\"Camera Sensor Views\", combined_view)\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    for camera in cameras:\n",
    "        camera.destroy()\n",
    "    vehicle.destroy()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbaed28-a981-4205-938c-f4d187adca54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
